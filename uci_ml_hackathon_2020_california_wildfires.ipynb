{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# California Wildfires\n",
    "### Donated by: Casey Graff (graffc@uci.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* ### Task: 2D Classificaiton (similiar to image segmentation)\n",
    "* ### # of Instances: 10k train / 5k test (more upon request)\n",
    "* ### Data\n",
    "    * #### Input: 3D Image (# Channels, Height, Width)\n",
    "    * #### Output: 2D Classification Probabilites (Height, Width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Description\n",
    "\n",
    "This challenge dataset focuses on the spatiotemporal prediction problem of forecasting how wildfires will spread in 12 or 24 hour periods. \n",
    "\n",
    "**Active fires** are observed using the VIIRS (Visible Infrared Imaging Radiometer Suite) mounted on the Suomi National Polar-orbiting Partnership (NPP) satellite. \n",
    "\n",
    "These fires are influenced by **land cover**, **topography**, and **weather** (among others not captured in this dataset). \n",
    "\n",
    "All data sources have been rescaled to **375m / pixel**. Each image contains 30 x 30 pixels  for an effective real **area of 11.25km**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### I. VIIRS Fire Detections\n",
    "* 5 layers / time steps (T = 0, -12, -24, -36, -48 hours)\n",
    "* 2 targets (T = +12 hours, +24 hours)\n",
    "\n",
    "### II. Land Cover (LANDFIRE)\n",
    "* 17 layers (3 topographic, 10 vegetation, 4 fuel/canopy)\n",
    "\n",
    "### III. Meteorology (Rapid Refresh)\n",
    "* 2 time steps (T = 0, +12 hours) x 5 variables (temperature, humidity, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports + Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_REG_WIDTH = 7\n",
    "FIG_REG_ASPECT_RATIO = 1.75\n",
    "\n",
    "def set_fig_settings(fig_size=(32,10), font_size=16, font_scale=1.6):       \n",
    "    plt.rcParams['figure.figsize'] = fig_size\n",
    "    plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "    plt.rcParams[\"legend.framealpha\"] = 0\n",
    "\n",
    "    font = {'weight' : 'normal', 'size'   : font_size}\n",
    "\n",
    "    plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'data/uci_ml_hackathon_fire_dataset_2012-05-09_2013-01-01_10k_train.hdf5'\n",
    "\n",
    "with h5py.File(DATASET_PATH, 'r') as f:\n",
    "    train_data = {}\n",
    "    for k in list(f):\n",
    "        train_data[k] = f[k][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_fire_inds = np.where(\n",
    "    (np.sum(train_data['observed'][:,0],axis=(1,2)) > 50) & \n",
    "    (np.sum(train_data['observed'][:,1],axis=(1,2)) > 50) & \n",
    "    (np.sum(train_data['observed'][:,2],axis=(1,2)) > 50) & \n",
    "    (np.sum(train_data['observed'][:,3],axis=(1,2)) > 50) & \n",
    "    (np.sum(train_data['observed'][:,4],axis=(1,2)) > 50) & \n",
    "    (np.sum(train_data['target'][:,0],axis=(1,2)) > 50) \n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_POINT = large_fire_inds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. VIIRS Detections (Observed + Target)\n",
    "\n",
    "### Source: https://earthdata.nasa.gov/earth-observation-data/near-real-time/firms/viirs-i-band-active-fire-data\n",
    "\n",
    "### Resolution: ~375m -> 375m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape:', train_data['observed'].shape, '= (# of Instances, # of Timesteps/Lags, Width, Height)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_fig_settings((FIG_REG_WIDTH*2,FIG_REG_WIDTH*1.25))\n",
    "fig = plt.figure()\n",
    "\n",
    "lat = train_data['latitude'][TRAINING_POINT]\n",
    "lon = train_data['longitude'][TRAINING_POINT]\n",
    "datetime = pd.to_datetime(train_data['datetime'][TRAINING_POINT])\n",
    "\n",
    "fig.suptitle(f'Lat: {lat:.2f}, Lon: {lon:.2f}, Datetime: {datetime}')\n",
    "\n",
    "# Plot X detections\n",
    "for i in range(5):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.title(f'{-12 * (4-i)} hours')\n",
    "    plt.imshow(train_data['observed'][TRAINING_POINT][4-i])\n",
    "    plt.axis('off')\n",
    "\n",
    "# Plt Y detections\n",
    "for i in range(2):\n",
    "    plt.subplot(2,5,i+5+1)\n",
    "    plt.title(f'+{12 * (i+1)} hours')\n",
    "    plt.imshow(train_data['target'][TRAINING_POINT][i])\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Land Cover\n",
    "\n",
    "### Source: https://www.landfire.gov/\n",
    "### Resolution: 30m -> 375m\n",
    "\n",
    "#### Layers\n",
    "* 0: Aspect \n",
    "* 1: Canopy Bult Density\n",
    "* 2: Canopy Base Height\n",
    "* 3: Canopy Cover\n",
    "* 4: Canopy Height\n",
    "* 5: Elevelation\n",
    "* 6 to 15: Vegetation (Fractional Veg Class per layer)\n",
    "* 16: Slope\n",
    "\n",
    "#### Vegetation Layers\n",
    "* 6: No Data\n",
    "* 7: Sparse\n",
    "* 8: Tree\n",
    "* 9: Shrub\n",
    "* 10: Herb\n",
    "* 11: Water\n",
    "* 12: Barren\n",
    "* 13: Developed\n",
    "* 14: Snow-Ice\n",
    "* 15: Agriculture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAND_COVER_LAYER_NAME_TO_IND = {'ASP': 0, 'CBD': 1, 'CBH': 2, 'CC': 3, 'CH': 4, 'DEM': 5, 'EVT': 6, 'SLP': 16}\n",
    "VEGETATION_NAME_TO_IND = {'Nodata': 0, 'Sparse': 1, 'Tree': 2, 'Shrub': 3, 'Herb': 4, 'Water': 5, 'Barren': 6, 'Developed': 7, 'Snow-Ice': 8, 'Agriculture': 9}\n",
    "\n",
    "TOPO_NAMES = ['ASP', 'SLP', 'DEM']\n",
    "VEG_NAME = 'EVT'\n",
    "FUEL_NAMES = ['CBD', 'CBH', 'CC', 'CH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape:', train_data['land_cover'].shape, '= (# of Instances, # of Layers, Width, Height)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_fig_settings((FIG_REG_WIDTH*1.5,FIG_REG_WIDTH*.65))\n",
    "fig = plt.figure()\n",
    "\n",
    "fig.suptitle('Topography')\n",
    "for i, name in enumerate(TOPO_NAMES):\n",
    "    plt.subplot(1,len(TOPO_NAMES),i+1)\n",
    "    plt.imshow(train_data['land_cover'][TRAINING_POINT][LAND_COVER_LAYER_NAME_TO_IND[name]])\n",
    "    plt.title(name)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_fig_settings((FIG_REG_WIDTH*2,FIG_REG_WIDTH*.65))\n",
    "fig = plt.figure()\n",
    "\n",
    "fig.suptitle('Fuel')\n",
    "for i, name in enumerate(FUEL_NAMES):\n",
    "    plt.subplot(1,len(FUEL_NAMES),i+1)\n",
    "    plt.imshow(train_data['land_cover'][TRAINING_POINT][LAND_COVER_LAYER_NAME_TO_IND[name]])\n",
    "    plt.title(name)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_fig_settings((FIG_REG_WIDTH*2,FIG_REG_WIDTH*1.25))\n",
    "fig = plt.figure()\n",
    "\n",
    "fig.suptitle('Vegetation')\n",
    "for i, (name, ind) in enumerate(VEGETATION_NAME_TO_IND.items()):\n",
    "    plt.subplot(2,len(VEGETATION_NAME_TO_IND)//2,i+1)\n",
    "    plt.imshow(train_data['land_cover'][TRAINING_POINT][LAND_COVER_LAYER_NAME_TO_IND[VEG_NAME] + ind])\n",
    "    plt.title(name)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Weather\n",
    "\n",
    "### Source: https://rapidrefresh.noaa.gov/\n",
    "###  Resolution 13km -> 375m\n",
    "\n",
    "#### Timesteps\n",
    "* 0: T = 0 hours (closest measurement to observed VIIRS detections)\n",
    "* 1: T = 12 hours (closest measurement to taget VIIRS detections)\n",
    "\n",
    "#### Variables\n",
    "* 0: Temperature @ 2m (Kelvin)\n",
    "* 1: Relative Humidity @ 2m (%)\n",
    "* 2: U Wind Component @ 10m (m s**-1)\n",
    "* 3: V Wind Component @ 10m (m s**-1)\n",
    "* 4: Precipitation Rate (kg m**-2 s**-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METEOROLOGY_NAME_TO_IND = {'Temp': 0, 'Rel. Humid.': 1, 'U Wind Comp.': 2, 'V Wind Comp.': 3, 'Precip. Rate': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape:', train_data['meteorology'].shape, '= (# of Instances, Timesteps, # of Variables, Width, Height)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_fig_settings((FIG_REG_WIDTH*2,FIG_REG_WIDTH*.65))\n",
    "fig = plt.figure()\n",
    "\n",
    "fig.suptitle('Vegetation')\n",
    "for i, (name, ind) in enumerate(METEOROLOGY_NAME_TO_IND.items()):\n",
    "    plt.subplot(1,len(METEOROLOGY_NAME_TO_IND),i+1)\n",
    "    plt.imshow(train_data['meteorology'][TRAINING_POINT][0][ind])\n",
    "    plt.scatter([15], [15], c='red')\n",
    "    plt.title(name)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task / Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistence_model(x):\n",
    "    return scipy.ndimage.gaussian_filter(x, 1.7, output=np.float32)\n",
    "\n",
    "def compute_mse(y, y_hat):\n",
    "    return np.mean((y-y_hat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data['observed'][TRAINING_POINT,0]\n",
    "y = train_data['target'][TRAINING_POINT,0]\n",
    "y_pred = persistence_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,3,1)\n",
    "plt.imshow(x)\n",
    "plt.title('X (T = 0 hours)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(y_pred)\n",
    "plt.title('$\\hat{Y}$ (T = +12 hours)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(y)\n",
    "plt.title('Y (T = +12 hours)')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats = [persistence_model(train_data['observed'][i,0]) for i in range(len(train_data['observed']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mse_12hour = compute_mse(train_data['target'][:,0], y_hats)\n",
    "mse_24hour = compute_mse(train_data['target'][:,1], y_hats)\n",
    "\n",
    "print(f'MSE: 12 Hour Target = {mse_12hour:.4f}, 24 Hour Target = {mse_24hour:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}